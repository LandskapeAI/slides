<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>Triplet Attention</title>


<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link rel="stylesheet" href="/slides/reveal-js/css/reset.css">
<link rel="stylesheet" href="/slides/reveal-js/css/reveal.css"><link rel="stylesheet" href="/slides/reveal-js/css/theme/white.css" id="theme">
<link rel="stylesheet" href="/slides/highlight-js/default.min.css">
    
  </head>
  <body>
    
    <style>
      #logo {
        position: absolute;
        top: 1%;
        left: 1%;
        width: 25%;
      }
    </style>
    <img id="logo" src="images/wacv.png" alt="">
    
    <div class="reveal">
      <div class="slides">
  

    <section><h3 id="rotate-to-attend-convolutional-triplet-attention-module">Rotate to Attend: Convolutional Triplet Attention Module</h3>
<div style=" font-size: 32px; color: gray; ">
Diganta Misra, Trikay Nalamada,</br> Ajay Uppili Arasanipalai, Qibin Hou
</div>
<p align="center"
    style = "height:150px;" >
        <img src="images/diganta.png" style="border-radius: 5px"/>
        <img src="images/trikay.png" style="border-radius: 5px"/>
        <img src="images/ajay.png" style="border-radius: 5px"/>
        <img src="images/andrew.png" style="border-radius: 5px"/>
</p>
<p align="center"
    style = "height:100px;" >
        <img class="plain" src="images/landskape.png"/>&emsp;
        <img class="plain" src="images/iitg.png"/>&emsp;
        <img class="plain" src="images/illinois.png"/>&emsp;
        <img class="plain" src="images/nus.png"/>
</p></section>

  

    <section>

<section data-shortcode-section>
<h1 id="attention-in-computer-vision">Attention in Computer Vision</h1>
</section><section>
<h2 id="squeeze-excite-networks">Squeeze-Excite Networks</h2>
<img class="plain" src="images/se.png"/>
<p>First to efficiently model cross-channel relationship in feature maps by learning channel-specific weights</p>
</section><section>
<h2 id="cbam">CBAM</h2>
<img class="plain" src="images/cbam.png"/>
<p>Fused channel and spatial attenion into a single module for visual recognition.</p>
</section><section>
<h2 id="global-context-networks">Global-Context Networks</h2>
<img width="30%" class="plain" src="images/gcnet.png"/>
<p>Combines channel attention with non-local block to learn long-range dependancies</p>
</section><section>
<h2 id="shortcomings">Shortcomings</h2>
<ul>
<li>Treat Dimensions Independently</li>
<li>Computationally Expensive</li>
<li>Information Bottlenecks</li>
</ul>

</section>
</section><section>


<section data-shortcode-section>
<h1 id="cross-dimensional-interaction">Cross-Dimensional Interaction</h1>
</section><section>
<p><img width="80%" class="plain" src="images/crossdim.png"></img></p>

</section>
</section><section>


<section data-shortcode-section>
<h1 id="triplet-attention">Triplet Attention</h1>
</section><section>
<figure>
<img class="plain" src='images/comp.png'/>
<figcaption class="text">
(a) Squeeze Excitation (b) CBAM; (c) Global Context Module; (d) Triplet Attention (ours)
</figcaption>
</figure>
</section><section>
<img class="plain" src='images/triplet.png'/>
<p>Triplet Attention Structural Design</p>

</section>
</section><section>


<section data-shortcode-section>
<h1 id="results">Results</h1>
</section><section>
<h2 id="image-classification">Image Classification</h2>
<img class="plain" src='images/results_image_classification.png'/>
</section><section>
<h2 id="object-detection">Object Detection</h2>
<img class="plain" src='images/results_object_detection.png'/>
</section><section>
<h2 id="gradcam">GradCAM</h2>
</section>
<section data-noprocess data-shortcode-slide
      data-transition="none"
      data-transition-speed="fast">
<img width="75%" class="plain" src="images/tape.png"/>
</section>
<section data-noprocess data-shortcode-slide
      data-transition="none"
      data-transition-speed="fast">
<img width="75%" class="plain" src="images/drill.png"/>
</section>
<section data-noprocess data-shortcode-slide
      data-transition="none"
      data-transition-speed="fast">
<img  class="plain" src="images/husky.png"/>
</section><section>

</section>
</section><section>
<p>Code and Pretrained Models:</p>
<p><a href="https://landskapeai.github.io/publication/triplet/">https://landskapeai.github.io/publication/triplet/</a></p>
</section><section>
<h3 align="left">References</h3>
<ol align="left" style="font-size: 22px">
    <li> Yue Cao,  Jiarui  Xu,  Stephen  Lin,  Fangyun  Wei,  and  HanHu. Gcnet: Non-local  networks  meet  squeeze-excitation networks  and  beyond. In Proceedings  of  the  IEEE  International Conference on Computer Vision Workshops, pages 0–0, 2019 </li>
    <li> Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation networks. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Jun 2018 </li>
    <li> Sanghyun  Woo,  Jongchan  Park,  Joon-Young  Lee,  and  InSo Kweon.   Cbam:  Convolutional block attention module.In The European Conference on Computer Vision (ECCV),September 2018. </li>
    <li> Yunpeng  Chen,  Yannis  Kalantidis,  Jianshu  Li,  Shuicheng Yan,  and  Jiashi  Feng. Aˆ2-nets:   Double  attention  networks. In Advances in Neural Information Processing Systems, pages 352–361, 2018. </li>
    <li> Zilin Gao, Jiangtao Xie, Qilong Wang, and Peihua Li. Global second-order pooling convolutional networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3024–3033, 2019 </li>
</ol>
</section>

</div>
      

    </div>
<script type="text/javascript" src=/slides/reveal-hugo/object-assign.js></script>

<a href="/slides/reveal-js/css/print/" id="print-location" style="display: none;"></a>
<script type="text/javascript">
  var printLocationElement = document.getElementById('print-location');
  var link = document.createElement('link');
  link.rel = 'stylesheet';
  link.type = 'text/css';
  link.href = printLocationElement.href + (window.location.search.match(/print-pdf/gi) ? 'pdf.css' : 'paper.css');
  document.getElementsByTagName('head')[0].appendChild(link);
</script>

<script type="application/json" id="reveal-hugo-site-params">null</script>
<script type="application/json" id="reveal-hugo-page-params">{"theme":"white"}</script>

<script src="/slides/reveal-js/js/reveal.js"></script>

<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }
  
  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };
  var revealHugoSiteParams = JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);
  var revealHugoPageParams = JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);
  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams));
  Reveal.initialize(options);
</script>


  
  
  <script type="text/javascript" src="/slides/reveal-js/plugin/markdown/marked.js"></script>
  
  <script type="text/javascript" src="/slides/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="/slides/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="/slides/reveal-js/plugin/zoom-js/zoom.js"></script>
  
  
  <script type="text/javascript" src="/slides/reveal-js/plugin/notes/notes.js"></script>



    
    
  </body>
</html>
